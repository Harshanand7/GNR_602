{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 14231,
          "sourceType": "datasetVersion",
          "datasetId": 9970
        }
      ],
      "dockerImageVersionId": 648,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshanand7/GNR_602/blob/main/GNR602_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "crawford_deepsat_sat4_path = kagglehub.dataset_download('crawford/deepsat-sat4')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "lfkmcXdQMM_k",
        "outputId": "6b184fb3-4088-4da0-ca4f-c560a29d125f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import cupy as cp\n",
        "from cuml.svm import SVC, LinearSVC\n",
        "from cuml.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "42cn7_3S3V5j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check the path\n",
        "print(\"Dataset path:\", crawford_deepsat_sat4_path)\n",
        "\n",
        "# List all files and folders in the dataset path\n",
        "print(\"Files:\", os.listdir(crawford_deepsat_sat4_path))\n"
      ],
      "metadata": {
        "id": "ylbnU5TIOTKq",
        "outputId": "99a05405-8966-4580-c5a6-8858d995105d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset path: /kaggle/input/deepsat-sat4\n",
            "Files: ['X_train_sat4.csv', 'X_test_sat4.csv', 'y_test_sat4.csv', 'y_train_sat4.csv', 'sat-4-full.mat', 'sat4annotations.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_set_fpath = os.path.join(crawford_deepsat_sat4_path, 'X_test_sat4.csv')\n",
        "y_train_set_fpath = os.path.join(crawford_deepsat_sat4_path, 'y_test_sat4.csv')\n"
      ],
      "metadata": {
        "id": "vr3uSwq9OXHj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt  # visualize satellite images\n",
        "from skimage.io import imshow  # visualize satellite images\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout  # components of network\n",
        "from keras.models import Sequential  # type of model\n",
        "\n",
        "# Load your data\n",
        "\n",
        "\n",
        "print('Loading Training Data')\n",
        "X_train = pd.read_csv(x_train_set_fpath)\n",
        "print('Loaded 28 x 28 x 4 images')\n",
        "\n",
        "Y_train = pd.read_csv(y_train_set_fpath)\n",
        "print('Loaded labels')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('We have', X_train.shape[0], 'examples and each example is a list of', X_train.shape[1], 'numbers with', Y_train.shape[1], 'possible classifications.')\n",
        "\n",
        "# Reshape the images to 28x28x4\n",
        "X_train_img = X_train.values.reshape([99999, 28, 28, 4]).astype(float)\n",
        "print(X_train_img.shape)\n"
      ],
      "metadata": {
        "id": "kEKYr1-xPA_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cbdcadc-66d5-4c3a-d8b8-b85012237c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Training Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage import color\n",
        "from skimage.feature import hog\n",
        "\n",
        "# Visualizing one image\n",
        "ix = 200  # Type a number between 0 and 99,999 inclusive\n",
        "\n",
        "# Ensure the image is in a format that imshow can handle\n",
        "img = np.squeeze(X_train_img[ix, :, :, 0:3])  # Only RGB channels\n",
        "img = img / 255.0  # Ensure values are between 0 and 1 for proper display\n",
        "\n",
        "# Check if the image is in the correct format for plotting\n",
        "if img.shape[-1] == 3:  # Check if the image has 3 channels (RGB)\n",
        "    plt.imshow(img.astype(float))  # Cast the image to float for display\n",
        "    plt.axis('off')  # Optional: Hide axes for better visibility\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Image format is incorrect. It may not have 3 channels.\")\n",
        "\n",
        "# Tells what the image is\n",
        "if Y_train.iloc[ix, 0] == 1:  # Use .iloc to access elements by integer index\n",
        "    print('Barren Land')\n",
        "elif Y_train.iloc[ix, 1] == 1:\n",
        "    print('Trees')\n",
        "elif Y_train.iloc[ix, 2] == 1:\n",
        "    print('Grassland')\n",
        "else:\n",
        "    print('Other')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TmjlzDn-Sio2",
        "outputId": "29c8fcae-4727-4025-86f6-230514cd920a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import color\n",
        "from skimage.feature import hog\n",
        "\n",
        "hog_features_map = []\n",
        "for i in range(99999):\n",
        "    image_sample = np.squeeze(X_train_img[i, :, :, 0:3])\n",
        "    image_gray = color.rgb2gray(image_sample)\n",
        "    feature= hog(image_gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
        "    hog_features_map.append(feature)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Convert HOG feature map to a numpy array\n",
        "hog_features_map = np.array(hog_features_map)\n",
        "\n",
        "# Initialize a MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the scaler and transform the features\n",
        "hog_features_normalized = scaler.fit_transform(hog_features_map)"
      ],
      "metadata": {
        "id": "U6FmuicV60e1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "lbp_features_map = []\n",
        "\n",
        "for i in range(99999):\n",
        "    image_sample = np.squeeze(X_train_img[i, :, :, 0:3])\n",
        "    image_gray = color.rgb2gray(image_sample)\n",
        "\n",
        "    # Extract LBP image\n",
        "    lbp_img = local_binary_pattern(image_gray, P=8, R=1, method='uniform')\n",
        "\n",
        "    # Histogram with 59 bins for 'uniform' patterns\n",
        "    hist, _ = np.histogram(lbp_img.ravel(), bins=np.arange(0, 60), range=(0, 59))\n",
        "\n",
        "    # Normalize histogram\n",
        "    hist = hist.astype(\"float\")\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "\n",
        "    # Append to list\n",
        "    lbp_features_map.append(hist)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxRDN-zbsjMW",
        "outputId": "1f042c8f-9d4f-4b07-e1bc-bfd8c44fda7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/skimage/feature/texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def extract_gabor_features(img):\n",
        "    # Define Gabor kernels (different orientations and scales)\n",
        "    kernels = []\n",
        "    for theta in np.arange(0, np.pi, np.pi / 4):  # 4 orientations\n",
        "        for lamda in [2, 4]:  # 2 wavelengths\n",
        "            kernels.append(cv2.getGaborKernel((21, 21), 5.0, theta, lamda, 1.0, 0, ktype=cv2.CV_32F))\n",
        "\n",
        "    gabor_features = []\n",
        "    for kernel in kernels:\n",
        "        filtered_img = cv2.filter2D(img, cv2.CV_32F, kernel)\n",
        "        gabor_features.append(filtered_img.mean())\n",
        "\n",
        "    return np.array(gabor_features)\n",
        "\n",
        "gabor_features_map = []\n",
        "for i in range(99999):\n",
        "    img = np.squeeze(X_train_img[i, :, :, 0:3])\n",
        "    # Convert image to uint8 before color conversion\n",
        "    img = img.astype(np.uint8)\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  # Convert to grayscale\n",
        "    gabor_features = extract_gabor_features(img_gray)\n",
        "    gabor_features_map.append(gabor_features)\n",
        "\n",
        "gabor_features_map = np.array(gabor_features_map)"
      ],
      "metadata": {
        "id": "atXClcqXNbni"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import color\n",
        "import cv2\n",
        "\n",
        "def extract_color_histogram(img, bins=16):\n",
        "    # Convert image to HSV color space\n",
        "    # Convert image to uint8 before color conversion\n",
        "    img = img.astype(np.uint8)\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Extract histograms for Hue, Saturation, and Value channels\n",
        "    hist_hue = cv2.calcHist([img_hsv], [0], None, [bins], [0, 256])\n",
        "    hist_saturation = cv2.calcHist([img_hsv], [1], None, [bins], [0, 256])\n",
        "    hist_value = cv2.calcHist([img_hsv], [2], None, [bins], [0, 256])\n",
        "\n",
        "    # Normalize histograms\n",
        "    hist_hue = hist_hue / hist_hue.sum()\n",
        "    hist_saturation = hist_saturation / hist_saturation.sum()\n",
        "    hist_value = hist_value / hist_value.sum()\n",
        "\n",
        "    # Concatenate histograms into a single feature vector\n",
        "    return np.concatenate([hist_hue.flatten(), hist_saturation.flatten(), hist_value.flatten()])\n",
        "\n",
        "color_histograms = []\n",
        "for i in range(99999):\n",
        "    img = np.squeeze(X_train_img[i, :, :, 0:3])\n",
        "    color_hist = extract_color_histogram(img)\n",
        "    color_histograms.append(color_hist)\n",
        "\n",
        "color_histograms = np.array(color_histograms)"
      ],
      "metadata": {
        "id": "e44bFwS2NUhE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_features_handcrafted = np.concatenate((hog_features_map, lbp_features_map), axis=1)\n"
      ],
      "metadata": {
        "id": "PW3sBDvK7HDp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_features_handcrafted_1 = np.concatenate((combined_features_handcrafted, color_histograms, gabor_features_map), axis=1)\n",
        "combined_features = combined_features_handcrafted_1"
      ],
      "metadata": {
        "id": "fK9p__z5NuTX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert to GPU arrays (if you want to use cuML)\n",
        "import cupy as cp\n",
        "X_train_f_gpu = cp.asarray(combined_features)\n",
        "Y_train_gpu = cp.asarray(Y_train)\n",
        "\n",
        "# Check the shape of the combined features\n",
        "print('Shape of combined features:', combined_features.shape)\n",
        "\n",
        "# Train-test split on GPU\n",
        "from cuml.model_selection import train_test_split\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_train_f_gpu, Y_train_gpu, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to single class (0, 1, 2, 3) for multi-class classification\n",
        "y_train_f = cp.argmax(y_train_f, axis=1)\n",
        "y_test_f = cp.argmax(y_test_f, axis=1)\n"
      ],
      "metadata": {
        "id": "tdTbdn-IPr5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84fd13d7-3283-4097-b79d-5ce9b021a239"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of combined features: (99999, 259)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train One-vs-One SVM using cuML\n",
        "from cuml.svm import SVC\n",
        "from sklearn.metrics import accuracy_score # Import accuracy_score\n",
        "from sklearn.metrics import classification_report # Import classification report\n",
        "\n",
        "# One-vs-One\n",
        "svm_ovo = SVC(kernel='linear')  # Removed decision_function_shape\n",
        "svm_ovo.fit(X_train_f, y_train_f)\n",
        "y_pred_ovo = svm_ovo.predict(X_test_f)\n",
        "ovo_accuracy = accuracy_score(y_test_f.get(), y_pred_ovo.get()) # Use .get() to convert to numpy array if needed\n",
        "print(\"OvO Accuracy:\", ovo_accuracy)"
      ],
      "metadata": {
        "id": "NV3mnrCtQUyv",
        "outputId": "c2e662ee-b4d9-4513-aea2-09c4ed4a33e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-04-26 22:51:54.690] [CUML] [warning] SVC with the linear kernel can be much faster using the specialized solver provided by LinearSVC. Consider switching to LinearSVC if tranining takes too long.\n",
            "OvO Accuracy: 0.9508475423771189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test_f.get(), y_pred_ovo.get()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujBxPG6nrfd2",
        "outputId": "f94ae288-a5fc-4262-a657-4d813c5d3293"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96      5153\n",
            "           1       0.95      0.96      0.95      4021\n",
            "           2       0.89      0.87      0.88      3624\n",
            "           3       0.97      0.98      0.97      7201\n",
            "\n",
            "    accuracy                           0.95     19999\n",
            "   macro avg       0.94      0.94      0.94     19999\n",
            "weighted avg       0.95      0.95      0.95     19999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cuml.svm import SVC, LinearSVC\n",
        "\n",
        "# --- OvR (Linear Kernel) ---\n",
        "svm_ovr = LinearSVC(multi_class='ovr')  # Explicit OvR\n",
        "svm_ovr.fit(X_train_f, y_train_f)\n",
        "y_pred_ovr = svm_ovr.predict(X_test_f)\n",
        "print(\"\\nOvR Results:\")\n",
        "print(classification_report(y_test_f.get(), y_pred_ovr.get()))\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test_f.get(), y_pred_ovr.get()))"
      ],
      "metadata": {
        "id": "8AXCZK3AMZhe",
        "outputId": "06d51111-0bbe-4bf3-a7e1-a50d15fb6781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-04-26 23:05:24.817] [CUML] [warning] L-BFGS: max iterations reached\n",
            "[2025-04-26 23:05:24.817] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
            "[2025-04-26 23:05:29.927] [CUML] [warning] L-BFGS: max iterations reached\n",
            "[2025-04-26 23:05:29.927] [CUML] [warning] Maximum iterations reached before solver is converged. To increase model accuracy you can increase the number of iterations (max_iter) or improve the scaling of the input data.\n",
            "\n",
            "OvR Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      5153\n",
            "           1       0.88      0.93      0.91      4021\n",
            "           2       0.85      0.79      0.82      3624\n",
            "           3       0.93      0.93      0.93      7201\n",
            "\n",
            "    accuracy                           0.91     19999\n",
            "   macro avg       0.90      0.90      0.90     19999\n",
            "weighted avg       0.91      0.91      0.91     19999\n",
            "\n",
            "OvR Accuracy: 0.912045602280114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib  # or use pickle\n",
        "\n",
        "# Saving the OvO model\n",
        "joblib.dump(svm_ovo, 'svm_ovo_model.pkl')\n",
        "\n",
        "# Saving the OvR model\n",
        "joblib.dump(svm_ovr, 'svm_ovr_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RZNeC-tIQvK",
        "outputId": "dd7b71db-c5c6-4271-8098-b734c66fed00"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_ovr_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the OvO model\n",
        "svm_ovo_loaded = joblib.load('svm_ovo_model.pkl')\n",
        "\n",
        "# Loading the OvR model\n",
        "svm_ovr_loaded = joblib.load('svm_ovr_model.pkl')\n"
      ],
      "metadata": {
        "id": "Qxx62UXHWeev"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ovr = svm_ovr_loaded.predict(X_test_f)\n",
        "print(\"\\nOvR Results:\")\n",
        "print(classification_report(y_test_f.get(), y_pred_ovr.get()))\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test_f.get(), y_pred_ovr.get()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_vHvogAWiEt",
        "outputId": "d160661f-91cb-4e4c-fe19-b9a6c1ac9ab9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OvR Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      5153\n",
            "           1       0.88      0.93      0.91      4021\n",
            "           2       0.85      0.79      0.82      3624\n",
            "           3       0.93      0.93      0.93      7201\n",
            "\n",
            "    accuracy                           0.91     19999\n",
            "   macro avg       0.90      0.90      0.90     19999\n",
            "weighted avg       0.91      0.91      0.91     19999\n",
            "\n",
            "OvR Accuracy: 0.912045602280114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ovo = svm_ovo_loaded.predict(X_test_f)\n",
        "print(\"\\nOvR Results:\")\n",
        "print(classification_report(y_test_f.get(), y_pred_ovo.get()))\n",
        "print(\"OvR Accuracy:\", accuracy_score(y_test_f.get(), y_pred_ovo.get()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTQqd-ubWlll",
        "outputId": "f99ddc53-41f7-4c14-d1c9-2f302e5e06a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OvR Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96      5153\n",
            "           1       0.95      0.96      0.95      4021\n",
            "           2       0.89      0.87      0.88      3624\n",
            "           3       0.97      0.98      0.97      7201\n",
            "\n",
            "    accuracy                           0.95     19999\n",
            "   macro avg       0.94      0.94      0.94     19999\n",
            "weighted avg       0.95      0.95      0.95     19999\n",
            "\n",
            "OvR Accuracy: 0.9508475423771189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ohR2PjGJWuAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}